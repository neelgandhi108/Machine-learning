{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TextGeneration.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2cwRRChZarLB","colab_type":"text"},"source":["**You know the deal by now, let's get started by importing our dependencies**"]},{"cell_type":"code","metadata":{"id":"tcnPK4QJX4h9","colab_type":"code","outputId":"0d8f618e-9aa5-4562-ee53-052ff1eb314d","executionInfo":{"status":"ok","timestamp":1566848027473,"user_tz":240,"elapsed":2000,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjwE097euDwbWe6DLsA9jrqnIHFFDD2-2g5QsSdA=s64","userId":"14853192264485050012"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import keras\n","import numpy as np\n","import random"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Gh_SPAjraxcI","colab_type":"text"},"source":["**Next, we need to load the data. It can be any text file. I decided on a text file of the writings of Nietzsche because it didn't need any preprocessing and uses the io library.**"]},{"cell_type":"code","metadata":{"id":"_h6S2_fq_841","colab_type":"code","outputId":"f00f6be4-f941-48b4-978a-76562c3786af","executionInfo":{"status":"ok","timestamp":1566848065384,"user_tz":240,"elapsed":271,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDjwE097euDwbWe6DLsA9jrqnIHFFDD2-2g5QsSdA=s64","userId":"14853192264485050012"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import io\n","path = keras.utils.data_utils.get_file(\n","    'nietzsche.txt',\n","    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","with io.open(path, encoding='utf-8') as f:\n","    text = f.read().lower()\n","print(len(text))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["600893\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5hQMO99EXyE3","colab_type":"text"},"source":["**Now we assign characters to a numerical value. This makes it easier for the model to predict which character comes next.**"]},{"cell_type":"code","metadata":{"id":"kBvmmNxKAQNp","colab_type":"code","outputId":"ddc2b28e-7800-4ed3-c2ea-f7704e87cb7c","executionInfo":{"status":"ok","timestamp":1565370387372,"user_tz":240,"elapsed":2700,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/-3ErEfX8LneA/AAAAAAAAAAI/AAAAAAAAJXQ/UgP90W3bjV0/s64/photo.jpg","userId":"14853192264485050012"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total chars: 57\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hnNEqrVYYVQ3","colab_type":"text"},"source":["**Next, we create multidimensional arrays out of the text data that we inputed so that the entire corpus of text is enumerated (is assigned a number instead of a character). This will be used for training and makes everything more coherent.**"]},{"cell_type":"code","metadata":{"id":"Qg92P-wHAU3N","colab_type":"code","colab":{}},"source":["sentences = []\n","next_chars = []\n","for i in range(0, len(text) - 40, 3):\n","    sentences.append(text[i: i + 40])\n","    next_chars.append(text[i + 40])\n","\n","x = np.zeros((len(sentences), 40, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KJiXtDEZbLi_","colab_type":"text"},"source":["**Now, let's build the model with an LSTM layer**\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"T_zsIphcAa6t","colab_type":"code","outputId":"65f9fcf8-fccb-40f4-b992-fe8c58ea35bc","executionInfo":{"status":"ok","timestamp":1563307911373,"user_tz":240,"elapsed":586,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/-3ErEfX8LneA/AAAAAAAAAAI/AAAAAAAAJXQ/UgP90W3bjV0/s64/photo.jpg","userId":"14853192264485050012"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["model = keras.models.Sequential()\n","model.add(keras.layers.LSTM(128, input_shape=(40, len(chars))))\n","model.add(keras.layers.Dense(len(chars), activation='softmax'))\n","\n","optimizer = keras.optimizers.RMSprop(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0716 20:11:50.872472 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0716 20:11:50.923416 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0716 20:11:50.933299 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0716 20:11:51.279042 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0716 20:11:51.291764 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"pgt2LBkDZhzc","colab_type":"text"},"source":["**This function will compare the sample predictions with the original text. The temperature represents how accurate or confident the model's predictions will be.**"]},{"cell_type":"code","metadata":{"id":"HF9o0C9DAhVH","colab_type":"code","colab":{}},"source":["def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1o4MuCL6bWGj","colab_type":"text"},"source":["**Next, train the model. It is recommended that at least 20 epochs are given to the model, however this can take quite a while so be prepared. The output text should be around 400 characters.**"]},{"cell_type":"code","metadata":{"id":"g2F0MBGAA32f","colab_type":"code","outputId":"4f17b092-81df-402d-e169-ccddf620ec00","executionInfo":{"status":"ok","timestamp":1563308380476,"user_tz":240,"elapsed":464590,"user":{"displayName":"Adam Eubanks","photoUrl":"https://lh3.googleusercontent.com/-3ErEfX8LneA/AAAAAAAAAAI/AAAAAAAAJXQ/UgP90W3bjV0/s64/photo.jpg","userId":"14853192264485050012"}},"colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["model.fit(x, y, batch_size=18, epochs=1)\n","start_index = random.randint(0, len(text) - 40 - 1)\n","for diversity in [0.2, 0.5, 1.0, 1.2]:\n","    generated = ''\n","    sentence = text[start_index: start_index + 40]\n","    generated += sentence\n","\n","    for i in range(400):\n","        x_pred = np.zeros((1, 40, len(chars)))\n","        for t, char in enumerate(sentence):\n","            x_pred[0, t, char_indices[char]] = 1.\n","\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        next_index = sample(preds, diversity)\n","        next_char = indices_char[next_index]\n","\n","        generated += next_char\n","        sentence = sentence[1:] + next_char\n","with open('example.txt', 'w') as f:\n","    f.write(generated)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0716 20:11:56.292767 140344017909632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0716 20:11:56.950916 140344017909632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/1\n","200285/200285 [==============================] - 458s 2ms/step - loss: 1.9765\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-HzoamuVbY4R","colab_type":"text"},"source":["**Finally, save the sample text to your computer (optional)**"]},{"cell_type":"code","metadata":{"id":"Ya8tF_K8B09t","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download('example.txt')"],"execution_count":0,"outputs":[]}]}